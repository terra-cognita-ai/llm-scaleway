# vLLM runtime
VLLM_IMAGE=vllm/vllm-openai:latest
MODEL_ID=mistralai/Ministral-3-8B-Instruct-2512
SERVED_MODEL_NAME=ministral-8b
VLLM_PORT=8000
VLLM_BIND_IP=0.0.0.0
# Comma-separated list of CIDRs allowed to reach VLLM_PORT on the host firewall.
# Example: VLLM_ALLOWED_CIDRS=51.15.10.20/32,10.0.0.0/8
VLLM_ALLOWED_CIDRS=
VLLM_DTYPE=float16
GPU_MEMORY_UTILIZATION=0.90
MAX_MODEL_LEN=8192
MAX_NUM_SEQS=24
HF_CACHE_DIR=/data/models

# Optional: required if model access is gated on Hugging Face
HUGGING_FACE_HUB_TOKEN=

# Scaleway deploy values
SCW_ZONE=fr-par-2
SCW_COMMERCIAL_TYPE=L4-1-24G
SCW_IMAGE=
SCW_IMAGE_FALLBACK=ubuntu_jammy
SCW_SERVER_NAME=llm-ministral-vllm
SCW_VOLUME_SIZE_GB=80
SCW_ROOT_VOLUME=sbs:80GB
SCW_SSH_USER=ubuntu
SCW_SSH_PUBLIC_KEY_PATH=$HOME/.ssh/scaleway.pub
SCW_SSH_PRIVATE_KEY_PATH=
