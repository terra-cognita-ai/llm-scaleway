services:
  vllm:
    image: ${VLLM_IMAGE:-vllm/vllm-openai:latest}
    container_name: vllm-ministral
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "${VLLM_BIND_IP:-0.0.0.0}:${VLLM_PORT:-8000}:8000"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
      - LD_LIBRARY_PATH=/usr/local/lib:/usr/lib/x86_64-linux-gnu
    volumes:
      - ${HF_CACHE_DIR:-/data/models}:/root/.cache/huggingface
    command:
      - --model
      - ${MODEL_ID:-mistralai/Ministral-3-8B-Instruct-2512}
      - --dtype
      - ${VLLM_DTYPE:-float16}
      - --gpu-memory-utilization
      - ${GPU_MEMORY_UTILIZATION:-0.90}
      - --max-model-len
      - ${MAX_MODEL_LEN:-8192}
      - --max-num-seqs
      - ${MAX_NUM_SEQS:-24}
      - --served-model-name
      - ${SERVED_MODEL_NAME:-ministral-8b}
